{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e3449d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, regularizers\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.initializers import RandomNormal\n",
    "from tensorflow.keras.optimizers import legacy\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e8f8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['A', 'd', 'L/d', 'fc', 'fyl', 'fys', 'ρl', 'ρs','γl','γs','n']\n",
    "y_labels = ['yield_dis', 'yield_load', 'peak_dis', 'peak_load', 'ultimate_dis']\n",
    "\n",
    "df = pd.read_csv('NOFRP01.csv', header=None,names=features + y_labels)\n",
    "\n",
    "X = df[features].values\n",
    "y = df[y_labels].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db24139",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_X = MinMaxScaler()\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "\n",
    "scaler_y = MinMaxScaler()\n",
    "y_scaled = scaler_y.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27031e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f5dc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(15, input_dim=11, activation='relu', kernel_initializer=RandomNormal())) \n",
    "model.add(Dense(9, activation='relu', kernel_initializer=RandomNormal()))\n",
    "model.add(Dense(5, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba75a18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = legacy.Adam(learning_rate=0.01)\n",
    "model.compile(optimizer=opt, loss='mean_absolute_error', metrics=['mean_squared_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7939b6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train_tf, y_train_tf, epochs=300, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba25f233",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r_squared = r2_score(y_test, y_pred)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "print(\"R2:\",r_squared)\n",
    "print(\"Mean Absolute Percentage Error:\", mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5182a85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ot = scaler_y.inverse_transform(y_test)\n",
    "y_op = scaler_y.inverse_transform(y_pred)\n",
    "\n",
    "mse_per_neuron = [mean_squared_error(y_ot[:, i], y_op[:, i]) for i in range(y_ot.shape[1])]\n",
    "mae_per_neuron = [mean_absolute_error(y_ot[:, i], y_op[:, i]) for i in range(y_ot.shape[1])]\n",
    "rmse_per_neuron = [np.sqrt(mse) for mse in mse_per_neuron]\n",
    "r2_per_neuron = [r2_score(y_ot[:, i],y_op[:, i]) for i in range(y_ot.shape[1])]\n",
    "mape_per_neuron = [mean_absolute_percentage_error(y_ot[:, i], y_op[:, i]) for i in range(y_ot.shape[1])]\n",
    "\n",
    "error_df = pd.DataFrame({'Neuron': y_labels, 'MAE': mae_per_neuron , 'RMSE': rmse_per_neuron, 'R2': r2_per_neuron, 'MAPE': mape_per_neuron})\n",
    "\n",
    "display(error_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc70ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(y_ot)\n",
    "df.to_excel('/Users/liuge/Desktop/Data/outputpred11.xlsx', index=False)\n",
    "df = pd.DataFrame(y_op)\n",
    "df.to_excel('/Users/liuge/Desktop/Data/outputpred22.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e37a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred0 = model.predict(X_train)\n",
    "\n",
    "mse = mean_squared_error(y_train, y_pred0)\n",
    "mae = mean_absolute_error(y_train, y_pred0)\n",
    "rmse = np.sqrt(mse)\n",
    "r_squared = r2_score(y_train, y_pred0)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "print(\"R2:\",r_squared)\n",
    "print(\"Mean Absolute Error:\", mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05222ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ot1 = scaler_y.inverse_transform(y_train)\n",
    "y_op1 = scaler_y.inverse_transform(y_pred0)\n",
    "\n",
    "mse_per_neuron = [mean_squared_error(y_ot1[:, i], y_op1[:, i]) for i in range(y_ot1.shape[1])]\n",
    "mae_per_neuron = [mean_absolute_error(y_ot1[:, i], y_op1[:, i]) for i in range(y_ot1.shape[1])]\n",
    "rmse_per_neuron = [np.sqrt(mse) for mse in mse_per_neuron]\n",
    "r2_per_neuron = [r2_score(y_ot1[:, i],y_op1[:, i]) for i in range(y_ot1.shape[1])]\n",
    "mape_per_neuron = [mean_absolute_percentage_error(y_ot1[:, i], y_op1[:, i]) for i in range(y_ot1.shape[1])]\n",
    "\n",
    "error_df = pd.DataFrame({'Neuron': y_labels, 'MAE': mae_per_neuron , 'RMSE': rmse_per_neuron, 'R2': r2_per_neuron, 'MAPE': mape_per_neuron})\n",
    "\n",
    "display(error_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e07d488",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(y_ot1)\n",
    "df.to_excel('/Users/liuge/Desktop/Data/outputpred33.xlsx', index=False)\n",
    "df = pd.DataFrame(y_op1)\n",
    "df.to_excel('/Users/liuge/Desktop/Data/outputpred44.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a643405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取模型对应的权重进行优化\n",
    "weights = model.get_weights()\n",
    "last_layer_weights = weights[-2]\n",
    "print(\"Last Layer Weights Shape:\", last_layer_weights.shape)\n",
    "neurons_to_optimize = last_layer_weights[:, 0]\n",
    "print(neurons_to_optimize.shape)\n",
    "\n",
    "# 定义萤火虫算法的参数\n",
    "num_fireflies = 400\n",
    "num_iterations = 500\n",
    "alpha = 0.7 # 随机参数\n",
    "beta_min = 0.5\n",
    "gamma = 1 # 吸引度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d39d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "fireflies = np.random.randn(num_fireflies, len(neurons_to_optimize))\n",
    "\n",
    "# 定义计算误差的函数\n",
    "def compute_error(predictions, true_values):\n",
    "    return np.mean((predictions - true_values) ** 2)\n",
    "\n",
    "def evaluate_firefly_brightness(weights_fixed, firefly, inputs, outputs):\n",
    "    layer_index = -2\n",
    "\n",
    "    test_weights = weights_fixed.copy()\n",
    "\n",
    "    test_weights[layer_index][:, 0] = firefly\n",
    "\n",
    "    model.set_weights(test_weights)\n",
    "\n",
    "    predictions = model.predict(inputs)\n",
    "\n",
    "    loss = compute_error(predictions, outputs)\n",
    "\n",
    "    return 1 / (loss + 1e-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec001047",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, outputs = X_train, y_train\n",
    "\n",
    "for iteration in range(num_iterations):\n",
    "    brightness = np.zeros(num_fireflies)\n",
    "    for i in range(num_fireflies):\n",
    "        brightness[i] = evaluate_firefly_brightness(weights, fireflies[i], inputs, outputs)\n",
    "\n",
    "    sorted_indices = np.argsort(brightness)\n",
    "    fireflies = fireflies[sorted_indices]\n",
    "    brightness = brightness[sorted_indices]\n",
    "\n",
    "    for i in range(num_fireflies):\n",
    "        for j in range(num_fireflies):\n",
    "            if brightness[j] > brightness[i]:\n",
    "                distance = np.linalg.norm(fireflies[i] - fireflies[j])\n",
    "                beta = beta_min + (1 - beta_min) * np.exp(-gamma * distance ** 2)\n",
    "                fireflies[i] = fireflies[i] * (1 - beta) + fireflies[j] * beta + alpha * (np.random.rand(len(neurons_to_optimize)) - 0.5)\n",
    "\n",
    "best_weights = fireflies[0]\n",
    "\n",
    "weights[-2][:, 0] = best_weights\n",
    "model.set_weights(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101113e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = model.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred1)\n",
    "mse = mean_squared_error(y_test, y_pred1)\n",
    "rmse = np.sqrt(mse)\n",
    "r_squared = r2_score(y_test, y_pred1)\n",
    "\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "print(\"R2:\",r_squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9efa5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ot = scaler_y.inverse_transform(y_test)\n",
    "y_op01 = scaler_y.inverse_transform(y_pred1)\n",
    "\n",
    "mse_per_neuron = [mean_squared_error(y_ot[:, i], y_op01[:, i]) for i in range(y_ot.shape[1])]\n",
    "mae_per_neuron = [mean_absolute_error(y_ot[:, i], y_op01[:, i]) for i in range(y_ot.shape[1])]\n",
    "rmse_per_neuron = [np.sqrt(mse) for mse in mse_per_neuron]\n",
    "r2_per_neuron = [r2_score(y_ot[:, i],y_op01[:, i]) for i in range(y_ot.shape[1])]\n",
    "\n",
    "error_df = pd.DataFrame({'Neuron': y_labels, 'MAE': mae_per_neuron , 'RMSE': rmse_per_neuron, 'R2': r2_per_neuron})\n",
    "\n",
    "display(error_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27026f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred0 = model.predict(X_train)\n",
    "\n",
    "mse = mean_squared_error(y_train, y_pred0)\n",
    "mae = mean_absolute_error(y_train, y_pred0)\n",
    "rmse = np.sqrt(mse)\n",
    "r_squared = r2_score(y_train, y_pred0)\n",
    "\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "print(\"R2:\",r_squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89f4cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ot1 = scaler_y.inverse_transform(y_train)\n",
    "y_op1 = scaler_y.inverse_transform(y_pred0)\n",
    "\n",
    "mse_per_neuron = [mean_squared_error(y_ot1[:, i], y_op1[:, i]) for i in range(y_ot1.shape[1])]\n",
    "mae_per_neuron = [mean_absolute_error(y_ot1[:, i], y_op1[:, i]) for i in range(y_ot1.shape[1])]\n",
    "rmse_per_neuron = [np.sqrt(mse) for mse in mse_per_neuron]\n",
    "r2_per_neuron = [r2_score(y_ot1[:, i],y_op1[:, i]) for i in range(y_ot1.shape[1])]\n",
    "\n",
    "error_df = pd.DataFrame({'Neuron': y_labels, 'MAE': mae_per_neuron , 'RMSE': rmse_per_neuron, 'R2': r2_per_neuron})\n",
    "\n",
    "display(error_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745c702f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf47456",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "print('Computing feature importance...')\n",
    "\n",
    "baseline_mae = mae\n",
    "results.append({'feature':'BASELINE', 'mae':baseline_mae})\n",
    "\n",
    "for k in tqdm(range(X_scaled.shape[1])):\n",
    "    save_col = X_scaled[:,k].copy()\n",
    "    np.random.shuffle(X_scaled[:,k])\n",
    "\n",
    "    y_pred_shuffled = model.predict(X_scaled)\n",
    "    mae = mean_absolute_error(y_scaled[:, 0], y_pred_shuffled[:, 0])\n",
    "    results.append({'feature': features[k], 'mae': mae})\n",
    "\n",
    "    X_scaled[:,k] = save_col\n",
    "\n",
    "print()\n",
    "df = pd.DataFrame(results)\n",
    "df = df.sort_values('mae')\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(df.feature, df.mae)\n",
    "plt.title('Feature Importance', size=16)\n",
    "plt.xlabel('MAE of yield_dis')\n",
    "plt.savefig(\"/Users/liuge/Desktop/my_plot1.png\")\n",
    "plt.show()\n",
    "\n",
    "df.to_csv('feature_importance1.csv', index=False)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfce76a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "print('Computing feature importance...')\n",
    "\n",
    "baseline_mae = mae\n",
    "results.append({'feature':'BASELINE', 'mae':baseline_mae})\n",
    "\n",
    "for k in tqdm(range(X_scaled.shape[1])):\n",
    "    save_col = X_scaled[:,k].copy()\n",
    "    np.random.shuffle(X_scaled[:,k])\n",
    "\n",
    "    y_pred0_shuffled = model.predict(X_scaled)\n",
    "    mae = mean_absolute_error(y_scaled[:, 1], y_pred0_shuffled[:, 1])\n",
    "    results.append({'feature': features[k], 'mae': mae})\n",
    "\n",
    "    X_scaled[:,k] = save_col\n",
    "\n",
    "print()\n",
    "df = pd.DataFrame(results)\n",
    "df = df.sort_values('mae')\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(df.feature, df.mae)\n",
    "plt.title('Feature Importance', size=16)\n",
    "plt.xlabel('MAE of yield_load')\n",
    "plt.savefig(\"/Users/liuge/Desktop/my_plot2.png\")\n",
    "plt.show()\n",
    "\n",
    "df.to_csv('feature_importance2.csv', index=False)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae442832",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "print('Computing feature importance...')\n",
    "\n",
    "baseline_mae = mae\n",
    "results.append({'feature':'BASELINE', 'mae':baseline_mae})\n",
    "\n",
    "for k in tqdm(range(X_scaled.shape[1])):\n",
    "    save_col = X_scaled[:,k].copy()\n",
    "    np.random.shuffle(X_scaled[:,k])\n",
    "\n",
    "    y_pred_shuffled = model.predict(X_scaled)\n",
    "    mae = mean_absolute_error(y_scaled[:, 2], y_pred_shuffled[:, 2])\n",
    "    results.append({'feature': features[k], 'mae': mae})\n",
    "\n",
    "    X_scaled[:,k] = save_col\n",
    "\n",
    "print()\n",
    "df = pd.DataFrame(results)\n",
    "df = df.sort_values('mae')\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(df.feature, df.mae)\n",
    "plt.title('Feature Importance', size=16)\n",
    "plt.xlabel('MAE of peak_dis')\n",
    "plt.savefig(\"/Users/liuge/Desktop/my_plot3.png\")\n",
    "plt.show()\n",
    "\n",
    "df.to_csv('feature_importance3.csv', index=False)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0cf111",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "print('Computing feature importance...')\n",
    "\n",
    "baseline_mae = mae\n",
    "results.append({'feature':'BASELINE', 'mae':baseline_mae})\n",
    "\n",
    "for k in tqdm(range(X_scaled.shape[1])):\n",
    "    save_col = X_scaled[:,k].copy()\n",
    "    np.random.shuffle(X_scaled[:,k])\n",
    "\n",
    "    y_pred_shuffled = model.predict(X_scaled)\n",
    "    mae = mean_absolute_error(y_scaled[:, 3], y_pred_shuffled[:, 3])\n",
    "    results.append({'feature': features[k], 'mae': mae})\n",
    "\n",
    "    X_scaled[:,k] = save_col\n",
    "\n",
    "print()\n",
    "df = pd.DataFrame(results)\n",
    "df = df.sort_values('mae')\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(df.feature, df.mae)\n",
    "plt.title('Feature Importance', size=16)\n",
    "plt.xlabel('MAE of peak_load')\n",
    "plt.savefig(\"/Users/liuge/Desktop/my_plot4.png\")\n",
    "plt.show()\n",
    "\n",
    "df.to_csv('feature_importance4.csv', index=False)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fce89fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "print('Computing feature importance...')\n",
    "\n",
    "baseline_mae = mae\n",
    "results.append({'feature':'BASELINE', 'mae':baseline_mae})\n",
    "\n",
    "for k in tqdm(range(X_scaled.shape[1])):\n",
    "    save_col = X_scaled[:,k].copy()\n",
    "    np.random.shuffle(X_scaled[:,k])\n",
    "\n",
    "    y_pred_shuffled = model.predict(X_scaled)\n",
    "    mae = mean_absolute_error(y_scaled[:, 4], y_pred_shuffled[:, 4])\n",
    "    results.append({'feature': features[k], 'mae': mae})\n",
    "\n",
    "    X_scaled[:,k] = save_col\n",
    "\n",
    "print()\n",
    "df = pd.DataFrame(results)\n",
    "df = df.sort_values('mae')\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(df.feature, df.mae)\n",
    "plt.title('Feature Importance', size=16)\n",
    "plt.xlabel('MAE of ultimate_dis')\n",
    "plt.savefig(\"/Users/liuge/Desktop/my_plot5.png\")\n",
    "plt.show()\n",
    "\n",
    "df.to_csv('feature_importance5.csv', index=False)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990f24a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
